import json
import numpy as np
from pathlib import Path
from sentence_transformers import SentenceTransformer


class EmbeddingTester:
    def __init__(self, embeddings_dir: str):
        self.embeddings_dir = Path(embeddings_dir)

        # ë°ì´í„° ë¡œë“œ
        print("ë°ì´í„° ë¡œë”© ì¤‘...")
        with open(self.embeddings_dir / "chunks_with_embeddings.json", 'r', encoding='utf-8') as f:
            self.chunks = json.load(f)

        self.embeddings = np.array([chunk['embedding'] for chunk in self.chunks])

        # ëª¨ë¸ ë¡œë“œ
        print("KURE ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = SentenceTransformer("nlpai-lab/KURE-v1")

        print(f"ë¡œë”© ì™„ë£Œ: {len(self.chunks)}ê°œ ì²­í¬")

    def search(self, query: str, top_k: int = 5, filters: dict = None):
        """
        ì¿¼ë¦¬ë¡œ ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ìƒìœ„ ëª‡ ê°œ ê²°ê³¼ ë°˜í™˜
            filters: í•„í„° ì¡°ê±´ (ì˜ˆ: {"category": "ê·¼ë¡œì‹œê°„", "doc_type": "standard_contract"})
        """
        print(f"\n{'='*80}")
        print(f"ğŸ” ì¿¼ë¦¬: {query}")
        print(f"{'='*80}")

        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.model.encode([query], convert_to_numpy=True)[0]

        # í•„í„°ë§
        if filters:
            filtered_indices = []
            for i, chunk in enumerate(self.chunks):
                match = True
                for key, value in filters.items():
                    if chunk.get(key) != value:
                        match = False
                        break
                if match:
                    filtered_indices.append(i)

            print(f"ğŸ“Œ í•„í„°: {filters}")
            print(f"   í•„í„° ì ìš© í›„: {len(filtered_indices)}ê°œ ì²­í¬")

            if len(filtered_indices) == 0:
                print("âš ï¸  í•„í„° ì¡°ê±´ì— ë§ëŠ” ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return []

            filtered_embeddings = self.embeddings[filtered_indices]
            filtered_chunks = [self.chunks[i] for i in filtered_indices]
        else:
            filtered_embeddings = self.embeddings
            filtered_chunks = self.chunks

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = np.dot(filtered_embeddings, query_embedding) / (
            np.linalg.norm(filtered_embeddings, axis=1) * np.linalg.norm(query_embedding)
        )

        # ìƒìœ„ kê°œ ì¶”ì¶œ
        top_indices = np.argsort(similarities)[::-1][:top_k]

        results = []
        print(f"\nğŸ“Š ìƒìœ„ {top_k}ê°œ ê²°ê³¼:\n")

        for rank, idx in enumerate(top_indices, 1):
            chunk = filtered_chunks[idx]
            similarity = similarities[idx]

            result = {
                "rank": rank,
                "similarity": float(similarity),
                "chunk": chunk
            }
            results.append(result)

            # ì¶œë ¥
            print(f"{rank}. ìœ ì‚¬ë„: {similarity:.4f} {'ğŸ”¥' if similarity > 0.7 else 'âœ“' if similarity > 0.6 else ''}")
            print(f"   ğŸ“„ ë¬¸ì„œ: {chunk.get('source', 'unknown')}")
            print(f"   ğŸ·ï¸  ì¹´í…Œê³ ë¦¬: {chunk.get('category', 'unknown')}")

            if chunk.get('doc_type'):
                print(f"   ğŸ“ íƒ€ì…: {chunk['doc_type']}")

            if chunk.get('keywords'):
                keywords = ", ".join(chunk['keywords'][:3])
                print(f"   ğŸ”– í‚¤ì›Œë“œ: {keywords}")

            # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
            content = chunk['content'].replace('\n', ' ')[:150]
            print(f"   ğŸ’¬ ë‚´ìš©: {content}...")
            print()

        return results

    def interactive_mode(self):
        """ëŒ€í™”í˜• ê²€ìƒ‰ ëª¨ë“œ"""
        print("\n" + "="*80)
        print("ğŸ¤– ì„ë² ë”© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ëŒ€í™”í˜• ëª¨ë“œ)")
        print("="*80)
        print("ì‚¬ìš©ë²•:")
        print("  - ì¿¼ë¦¬ ì…ë ¥: ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ë‚´ìš© ì…ë ¥")
        print("  - í•„í„°ë§: filter:category=ê·¼ë¡œì‹œê°„ í˜•íƒœë¡œ ì…ë ¥")
        print("  - ì¢…ë£Œ: 'q' ë˜ëŠ” 'exit' ì…ë ¥")
        print("="*80 + "\n")

        while True:
            try:
                query = input("ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: ").strip()

                if query.lower() in ['q', 'exit', 'quit', 'ì¢…ë£Œ']:
                    print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

                if not query:
                    continue

                # í•„í„° íŒŒì‹±
                filters = {}
                if "filter:" in query:
                    parts = query.split("filter:")
                    query = parts[0].strip()
                    filter_str = parts[1].strip()

                    for f in filter_str.split(","):
                        if "=" in f:
                            key, value = f.split("=", 1)
                            filters[key.strip()] = value.strip()

                # ê²€ìƒ‰ ì‹¤í–‰
                self.search(query, top_k=5, filters=filters if filters else None)

            except KeyboardInterrupt:
                print("\nì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"ì—ëŸ¬: {e}")

    def run_preset_tests(self):
        """ë¯¸ë¦¬ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰"""
        test_cases = [
            {
                "query": "ê·¼ë¡œì‹œê°„ì€ í•˜ë£¨ì— ëª‡ ì‹œê°„ê¹Œì§€ ê°€ëŠ¥í•œê°€ìš”?",
                "filters": None
            },
            {
                "query": "ìµœì €ì„ê¸ˆ 2025ë…„",
                "filters": {"category": "ì„ê¸ˆ"}
            },
            {
                "query": "ì—°ì°¨ íœ´ê°€ ê³„ì‚° ë°©ë²•",
                "filters": None
            },
            {
                "query": "ì±„ìš© ì‹œ ê°œì¸ì •ë³´ ìˆ˜ì§‘",
                "filters": {"doc_type": "manual"}
            },
            {
                "query": "ì§•ê³„ ì ˆì°¨",
                "filters": {"category": "ìƒë²Œ"}
            },
            {
                "query": "ì£¼ 52ì‹œê°„",
                "filters": {"doc_type": "employment_rules"}
            }
        ]

        print("\n" + "="*80)
        print("ğŸ§ª ì‚¬ì „ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰")
        print("="*80)

        for i, test in enumerate(test_cases, 1):
            print(f"\n[í…ŒìŠ¤íŠ¸ {i}/{len(test_cases)}]")
            self.search(test["query"], top_k=3, filters=test.get("filters"))

            if i < len(test_cases):
                input("\nâ¸ï¸  ë‹¤ìŒ í…ŒìŠ¤íŠ¸ë¡œ ë„˜ì–´ê°€ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")


if __name__ == "__main__":
    import sys

    project_root = Path(__file__).parent.parent.parent
    embeddings_dir = project_root / "ai/data/processed/embeddings"

    tester = EmbeddingTester(str(embeddings_dir))

    # ëª…ë ¹ì¤„ ì¸ì í™•ì¸
    if len(sys.argv) > 1:
        mode = sys.argv[1]

        if mode == "interactive" or mode == "i":
            # ëŒ€í™”í˜• ëª¨ë“œ
            tester.interactive_mode()

        elif mode == "test" or mode == "t":
            # ì‚¬ì „ ì •ì˜ í…ŒìŠ¤íŠ¸
            tester.run_preset_tests()

        else:
            # ì§ì ‘ ì¿¼ë¦¬
            query = " ".join(sys.argv[1:])
            tester.search(query, top_k=5)

    else:
        # ê¸°ë³¸: ëŒ€í™”í˜• ëª¨ë“œ
        print("\nì‚¬ìš©ë²•:")
        print("  python test_embeddings.py interactive  # ëŒ€í™”í˜• ëª¨ë“œ")
        print("  python test_embeddings.py test         # ì‚¬ì „ ì •ì˜ í…ŒìŠ¤íŠ¸")
        print("  python test_embeddings.py ê·¼ë¡œì‹œê°„     # ì§ì ‘ ì¿¼ë¦¬")
        print()

        choice = input("ëª¨ë“œ ì„ íƒ [1: ëŒ€í™”í˜•, 2: í…ŒìŠ¤íŠ¸, Enter: ëŒ€í™”í˜•]: ").strip()

        if choice == "2":
            tester.run_preset_tests()
        elif choice in ["3", "q", "exit"]:
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
        else:
            # ê¸°ë³¸ê°’: ëŒ€í™”í˜• ëª¨ë“œ
            tester.interactive_mode()
