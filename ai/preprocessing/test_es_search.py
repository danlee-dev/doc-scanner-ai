import os
import re
import json
from elasticsearch import Elasticsearch, helpers
from sentence_transformers import SentenceTransformer

# --- ì„¤ì • ---
# 1. ì¿¼ë¦¬ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
print("ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘... (KURE-v1)")
MODEL_NAME = "nlpai-lab/KURE-v1" # search.pyì—ì„œ í™•ì¸í•œ ëª¨ë¸ ì´ë¦„
try:
    model = SentenceTransformer(MODEL_NAME)
    model.max_seq_length = 512 # ì›ë³¸ search.pyì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
except Exception as e:
    print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨! '{MODEL_NAME}'ì´ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. (ì˜¤ë¥˜: {e})")
    print("ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜, ëª¨ë¸ ì´ë¦„ì„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
    exit()

# 2. Elasticsearch ì—°ê²°
# (í„°ë¯¸ë„ì—ì„œ set NO_PROXY=localhostë¥¼ ì‹¤í–‰í•´ì•¼ í•¨)
es = Elasticsearch("http://localhost:9200") 

# 3. ì¸ë±ìŠ¤ ì´ë¦„
INDEX_NAME = "docscanner_chunks"

# 4. ë¬¸ì„œ íƒ€ì… ë§¤í•‘ (ë¡œê·¸ ì¶œë ¥ìš©)
DOC_TYPE_MAP = {
    'interpretation': 'ë²•ë ¹í•´ì„ë¡€',
    'precedent': 'íŒë¡€',
    'labor_ministry': 'ê³ ìš©ë…¸ë™ë¶€',
    'manual': 'ë§¤ë‰´ì–¼(PDF)',
    'employment_rules': 'ì·¨ì—…ê·œì¹™(PDF)',
    'guide': 'ì•ˆë‚´ì„œ(PDF)',
    'leaflet': 'ë¦¬í”Œë¦¿(PDF)',
    'question': 'ì§ˆì˜(ë²•ë¥ )',
    'answer': 'ë‹µë³€(ë²•ë¥ )',
}
# -----------------

def search_es(query: str, top_k: int = 5, filter_source: str = None):
    """Elasticsearchì— ë²¡í„° ê²€ìƒ‰(KNN) ì‹¤í–‰ (í•„í„° í¬í•¨)"""
    
    # 1. ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
    print("\nì¿¼ë¦¬ ì„ë² ë”© ì¤‘...")
    try:
        query_vector = model.encode(query, normalize_embeddings=True).tolist()
    except Exception as e:
        print(f"ì¿¼ë¦¬ ì„ë² ë”© ì‹¤íŒ¨: {e}")
        return []
        
    print("Elasticsearchë¡œ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")

    # 2. Elasticsearch KNN ì¿¼ë¦¬ ìƒì„±
    knn_query = {
        "field": "embedding",
        "query_vector": query_vector,
        "k": top_k,
        "num_candidates": 100 
    }

    # 3. í•„í„°ê°€ ìˆë‹¤ë©´ KNN ì¿¼ë¦¬ ë‚´ë¶€ì— 'filter' ë¸”ë¡ ì¶”ê°€
    if filter_source:
        knn_query["filter"] = {
            "term": {
                "source": filter_source 
            }
        }
        print(f"(í•„í„° ì ìš©: source == '{filter_source}')")


    try:
        response = es.search(
            index=INDEX_NAME,
            knn=knn_query, 
            size=top_k,
            request_timeout=30
        )
        return response['hits']['hits']
        
    except Exception as e:
        print(f"ES ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def main():
    """ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ ë£¨í”„"""
    if not es.indices.exists(index=INDEX_NAME):
        print(f"ì˜¤ë¥˜: '{INDEX_NAME}' ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("4_index.pyë¥¼ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    print("\n" + "="*70)
    print("ğŸ‰ Elasticsearch ì„ë² ë”© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ëŒ€í™”í˜• ëª¨ë“œ)")
    print("="*70)
    print("\nì‚¬ìš©ë²•:")
    print("  - ê²€ìƒ‰: ì¿¼ë¦¬ ì…ë ¥")
    print("  - í•„í„°: @í•„í„°ëª… ì¶”ê°€ (ì˜ˆ: ìµœì €ì„ê¸ˆ @precedent)")
    print("  - ìƒìœ„ ê²°ê³¼: #ìˆ«ì ì¶”ê°€ (ì˜ˆ: ì—°ì°¨ #10)")
    print("  - ì¢…ë£Œ: 'q' ë˜ëŠ” 'exit' ì…ë ¥")
    print("\nì‚¬ìš© ê°€ëŠ¥í•œ í•„í„° ì˜ˆì‹œ:")
    print("  - @precedent (íŒë¡€ë§Œ)")
    print("  - @interpretation (ë²•ë ¹í•´ì„ë¡€ë§Œ)")
    print("  - @manual (ë§¤ë‰´ì–¼ë§Œ)")
    print("  - @employment_rules (ì·¨ì—…ê·œì¹™ë§Œ)")
    print("="*70 + "\n")

    while True:
        try:
            user_input = input("ê²€ìƒ‰ ì¿¼ë¦¬: ").strip()

            if user_input.lower() in ['q', 'exit', 'quit', 'ì¢…ë£Œ']:
                print("\ní…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not user_input:
                continue

            # --- íŒŒë¼ë¯¸í„° íŒŒì‹± ---
            query = user_input
            filter_source = None
            top_k = 5 # ê¸°ë³¸ 5ê°œ

            # 1. @ í•„í„° íŒŒì‹±
            if '@' in query:
                parts = query.split('@')
                query = parts[0].strip()
                filter_str = parts[1].strip().split()[0]
                filter_source = filter_str 
            
            # 2. # top_k íŒŒì‹±
            if '#' in query:
                parts = query.split('#')
                query = parts[0].strip()
                try:
                    top_k = int(parts[1].strip().split()[0])
                    top_k = min(max(top_k, 1), 20) # 1~20ê°œë¡œ ì œí•œ
                except ValueError:
                    print("ì˜ëª»ëœ ìˆ«ì í˜•ì‹. ê¸°ë³¸ 5ê°œë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
                    top_k = 5
            
            if not query:
                print("ê²€ìƒ‰ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            # --- ES ê²€ìƒ‰ ì‹¤í–‰ ---
            results = search_es(query, top_k=top_k, filter_source=filter_source)

            if not results:
                print("\n-> ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                print("="*70)
                continue

            # --- ê²°ê³¼ ë¡œê·¸ ì¶œë ¥ ---
            print(f"\n--- '{query}' ê²€ìƒ‰ ê²°ê³¼ (Top {len(results)}) ---")
            for i, hit in enumerate(results):
                source_data = hit['_source']
                source_type = source_data.get('source', 'unknown')
                
                print(f"\n[{i+1}] ìœ ì‚¬ë„: {hit['_score']:.4f}")
                print(f"  (ì¶œì²˜ íƒ€ì…: {DOC_TYPE_MAP.get(source_type, source_type)})") # ë§µí•‘ëœ ì´ë¦„ ì¶œë ¥
                
                # ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                content = source_data.get('text', '').replace('\n', ' ')[:200]
                print(f"  ë‚´ìš©: {content}...")
                print("-"*20)
            print("="*70)
                
        except KeyboardInterrupt:
            print("\ní…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"!!! ì „ì²´ ë£¨í”„ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()