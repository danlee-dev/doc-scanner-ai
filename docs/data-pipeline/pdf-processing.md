# 데이터 처리 파이프라인

## 개요

본 문서는 근로계약서 분석 AI 시스템의 데이터 처리 파이프라인을 설명합니다. PDF 문서 추출부터 청킹, 임베딩 생성까지의 전체 과정을 다룹니다.

## 1. 데이터 수집

### 1.1 원본 데이터

총 5개의 PDF 문서를 수집하여 사용:

| 문서명 | 유형 | 페이지 | 문자 수 |
|--------|------|--------|---------|
| 개정 표준근로계약서(2025년, 배포) | 계약서 양식 | 7 | 6,882 |
| '25년 채용절차의 공정화에 관한 법률 업무 매뉴얼 | 법률 매뉴얼 | 304 | 237,998 |
| 개정 표준취업규칙(2025년, 배포) | 취업 규칙 | 163 | 134,564 |
| 2025년 적용 최저임금 안내 | 안내문 | 2 | 3,685 |
| 채용절차의 공정화에 관한 법률 리플릿 | 리플릿 | 2 | 6,055 |

### 1.2 PDF 텍스트 추출

**도구**: pdfplumber

**구현**: `ai/preprocessing/pdf_extractor.py`

**출력 형식**:
```json
{
  "filename": "원본파일명.pdf",
  "text": "추출된 텍스트 (페이지 구분자 포함)",
  "metadata": {
    "pages": 페이지수,
    "char_count": 문자수
  }
}
```

**출력 위치**: `ai/data/processed/documents/standard_contracts/*.json`

### 1.3 향후 데이터 추가 계획

**법률 정보 API 연동 (진행 중)**

현재 open.law.go.kr 법률 정보 API 사용 신청 상태입니다. 승인 후 다음 데이터를 추가 수집 예정:

- 법령 정보
- 판례 정보
- 행정규칙
- 기타 법률 관련 문서

**추가 작업 계획**:
1. API 승인 후 데이터 수집
2. 새로운 문서에 맞는 청킹 전략 설계
3. 기존 674개 청크에 신규 청크 추가
4. 전체 데이터셋 재임베딩
5. Elasticsearch 인덱스 업데이트

Elasticsearch는 증분 인덱싱을 지원하므로, 기존 데이터를 유지하면서 신규 데이터를 추가할 수 있습니다.

## 2. 청킹 전략

### 2.1 문서별 청킹 방식

각 문서 유형에 맞는 청킹 전략을 적용하여 의미 단위로 분할:

#### 2.1.1 표준근로계약서 (제외됨)
- **처리 방식**: 청킹하지 않고 별도 체크리스트로 관리
- **이유**: 빈 양식 템플릿이므로 RAG 검색에 무의미
- **대체 방안**: 필수 필드 체크리스트 생성 (`required_contract_fields.json`)

#### 2.1.2 채용절차 법률 매뉴얼
- **방식**: 장/절 단위 분할
- **패턴**: `\d+\.\s+[가-힣]` (1. 제목 형식)
- **특징**: 제목과 내용을 병합하여 저장
- **필터링**: 50자 미만 청크 제외
- **청크 수**: 296개

#### 2.1.3 표준취업규칙
- **방식**: 조문 단위 분할
- **패턴**: `제\s*\d+\s*조` (제1조, 제2조 형식)
- **메타데이터**: 조문 번호, 제목, 카테고리
- **청크 수**: 367개

#### 2.1.4 최저임금 안내
- **방식**: 주제별 Q&A 분할
- **패턴**: `나요?`로 끝나는 질문 기준
- **특징**: 2025년 최저임금 정보 포함
- **청크 수**: 4개

#### 2.1.5 채용절차 리플릿
- **방식**: 채용 단계별 분할
- **단계**: 채용광고, 지원서 접수, 채용심사, 채용확정
- **특징**: 위반 사항 및 처벌 규정 추출
- **청크 수**: 7개

### 2.2 청크 메타데이터 구조

모든 청크는 다음 메타데이터를 포함:

```json
{
  "chunk_id": "uuid",
  "doc_type": "manual|employment_rules|guide|leaflet",
  "content": "실제 내용",
  "source": "원본 파일명",
  "category": "채용절차|근로시간|임금|휴가 등",
  "keywords": ["키워드1", "키워드2", ...],
  "page": 페이지번호
}
```

### 2.3 카테고리 분류

청크는 자동으로 다음 카테고리로 분류:

- **채용절차**: 303개
- **근로시간**: 77개
- **기타**: 71개
- **인사**: 56개
- **휴일휴가**: 54개
- **임금**: 47개
- **상벌**: 26개
- **총칙**: 23개
- **복리후생**: 15개
- **안전보건**: 2개

### 2.4 구현

**파일**: `ai/preprocessing/chunker.py`

**실행**:
```bash
cd ai/preprocessing
python chunker.py
```

**출력**:
- `ai/data/processed/chunks/all_chunks.json`: 전체 청크 (674개)
- `ai/data/processed/chunks/metadata.json`: 통계 정보

## 3. 임베딩 생성

### 3.1 임베딩 모델

**모델**: KURE-v1 (nlpai-lab/KURE-v1)
- **특징**: 한국어 법률 문서 특화 모델
- **차원**: 1024
- **최대 시퀀스 길이**: 512 토큰

**선택 이유**:
- 한국어 법률 용어에 최적화
- 일반 임베딩 모델 대비 법률 도메인 성능 우수
- 문맥 이해 능력 향상

### 3.2 임베딩 생성 과정

1. **텍스트 전처리**
   - 카테고리를 텍스트 앞에 추가: `[카테고리] 내용`
   - 상위 3개 키워드 추가: `내용\n키워드: 키워드1, 키워드2, 키워드3`

2. **배치 처리**
   - 배치 크기: 8 (메모리 효율성)
   - 진행률 표시: tqdm

3. **정규화**
   - normalize_embeddings: False (코사인 유사도 계산 시 정규화)

### 3.3 임베딩 성능

테스트 쿼리 결과 (상위 결과 유사도):

| 쿼리 | 유사도 | 문서 유형 |
|------|--------|-----------|
| 근로시간은 하루에 몇 시간까지 가능한가요? | 0.7022 | employment_rules |
| 최저임금은 얼마인가요? | 0.6919 | guide |
| 연차 휴가는 어떻게 계산하나요? | 0.6860 | employment_rules |
| 채용 시 개인정보를 요구할 수 있나요? | 0.7006 | manual |

### 3.4 구현

**파일**: `ai/preprocessing/embedder.py`

**실행**:
```bash
cd ai/preprocessing
python embedder.py
```

**출력**:
- `ai/data/processed/embeddings/chunks_with_embeddings.json`: 임베딩 포함 전체 청크
- `ai/data/processed/embeddings/embeddings.npy`: NumPy 배열 형태의 임베딩 (빠른 로딩용)
- `ai/data/processed/embeddings/embedding_metadata.json`: 임베딩 메타데이터

**소요 시간**: 약 32초 (674개 청크)

## 4. 계약서 필수 필드 체크리스트

### 4.1 개요

표준근로계약서는 RAG 검색용이 아닌 필수 항목 체크리스트로 활용합니다.

### 4.2 계약서 유형

5가지 유형별 필수 필드 정의:

| 유형 | 필드 수 | 특징 |
|------|---------|------|
| 정규직 | 11 | 기본 근로계약서 |
| 기간제 | 11 | 계약기간 명시 필수 |
| 연소근로자 | 12 | 친권자 동의 추가 |
| 건설일용 | 11 | 일당 계산 방식 |
| 단시간근로자 | 10 | 근로일별 시간표 필요 |

### 4.3 필드 정보

각 필드는 다음 정보를 포함:

```json
{
  "field_name": "필드명",
  "clause_number": "조항 번호",
  "required": true,
  "template": "양식 템플릿",
  "description": "설명",
  "regulation": "관련 규정"
}
```

### 4.4 활용

사용자 업로드 계약서 분석 시:
1. 계약서 유형 판별
2. 해당 유형의 필수 필드 목록 조회
3. 누락된 필드 확인
4. 누락 필드에 대한 규정 안내

**파일**: `ai/data/processed/required_contract_fields.json`

## 5. 전체 파일 구조

```
ai/
├── data/
│   ├── raw/
│   │   └── pdfs/                    # 원본 PDF 파일
│   └── processed/
│       ├── documents/
│       │   └── standard_contracts/  # 추출된 JSON (5개)
│       ├── chunks/
│       │   ├── all_chunks.json      # 전체 청크 (674개)
│       │   └── metadata.json        # 청크 통계
│       ├── embeddings/
│       │   ├── chunks_with_embeddings.json  # 임베딩 포함 청크
│       │   ├── embeddings.npy               # 임베딩 배열
│       │   └── embedding_metadata.json      # 임베딩 정보
│       └── required_contract_fields.json    # 필수 필드 체크리스트
└── preprocessing/
    ├── pdf_extractor.py             # PDF 텍스트 추출
    ├── chunker.py                   # 청킹 처리
    ├── embedder.py                  # 임베딩 생성
    ├── extract_contract_fields.py   # 필수 필드 추출
    └── test_embeddings.py           # 임베딩 테스트 도구
```

## 6. 성능 최적화

### 6.1 메모리 관리

- 배치 크기: 8 (메모리 절약)
- 최대 시퀀스 길이: 512 (KURE 모델 최대 길이)
- NumPy 배열 저장으로 빠른 로딩

### 6.2 검색 성능

- 코사인 유사도 사용
- 메타데이터 필터링 지원 (카테고리, 문서 유형 등)
- 상위 k개 결과 반환

## 7. 다음 단계

1. **Elasticsearch 설정**
   - 벡터 검색 인덱스 생성
   - 하이브리드 검색 (키워드 + 벡터)
   - 메타데이터 필터링

2. **RAG 시스템 구축**
   - 쿼리 처리 파이프라인
   - 컨텍스트 조합
   - LLM 통합

3. **계약서 분석 엔진**
   - 계약서 파싱
   - 필수 필드 체크
   - 위험 조항 탐지
   - 불공정 조항 식별

## 8. 참고 사항

### 8.1 의존성

```
pdfplumber==0.11.4
sentence-transformers==5.1.2
torch==2.9.0
transformers==4.57.1
numpy
tqdm
```

### 8.2 환경

- Python: 3.10
- Conda 환경: docscanner-py3.10
- GPU: Apple M3 Pro (MPS 지원)

### 8.3 테스트 도구

임베딩 품질 테스트:
```bash
cd ai/preprocessing
python test_embeddings.py interactive  # 대화형 모드
python test_embeddings.py test         # 사전 정의 테스트
python test_embeddings.py "쿼리"       # 직접 검색
```

## 9. 변경 이력

### 2025-10-27
- 초기 데이터 수집 및 청킹 구현
- KURE-v1 임베딩 모델 적용
- standard_contract를 별도 체크리스트로 분리
- 재청킹 및 재임베딩 완료 (736개 → 674개)
